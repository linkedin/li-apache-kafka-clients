/*
 * Copyright 2017 LinkedIn Corp. Licensed under the BSD 2-Clause License (the "License").â€¨ See License in the project root for license information.
 */

package com.linkedin.kafka.clients.largemessage;

import com.linkedin.kafka.clients.largemessage.errors.OffsetNotTrackedException;
import com.linkedin.kafka.clients.utils.TestUtils;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.record.TimestampType;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.kafka.common.serialization.Serializer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.testng.annotations.Test;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.UUID;

import static org.testng.Assert.assertEquals;
import static org.testng.Assert.assertNull;
import static org.testng.Assert.assertTrue;
import static org.testng.Assert.fail;

/**
 * Unit test for consumer record filter.
 */
public class ConsumerRecordsProcessorTest {

  @Test
  public void testFilter() throws Exception {
    // Create consumer record processor
    Serializer<String> stringSerializer = new StringSerializer();
    Serializer<LargeMessageSegment> segmentSerializer = new DefaultSegmentSerializer();
    ConsumerRecordsProcessor<String, String> consumerRecordsProcessor = createConsumerRecordsProcessor();

    // Let consumer record 0 be a normal record.
    String message0 = "message0";
    ConsumerRecord<byte[], byte[]> consumerRecord0 =
        new ConsumerRecord<>("topic", 0, 0, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(),
                             stringSerializer.serialize("topic", message0));

    // Let consumer record 1 be a large message.
    byte[] message1Bytes =
        segmentSerializer.serialize("topic",
                                    TestUtils.createLargeMessageSegment(UUID.randomUUID(), 0, 2, 20, 10));
    ConsumerRecord<byte[], byte[]> consumerRecord1 =
        new ConsumerRecord<>("topic", 0, 1, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), message1Bytes);

    // Construct the consumer records.
    List<ConsumerRecord<byte[], byte[]>> recordList = new ArrayList<>();
    recordList.add(consumerRecord0);
    recordList.add(consumerRecord1);
    Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> recordsMap = new HashMap<>();
    recordsMap.put(new TopicPartition("topic", 0), recordList);
    ConsumerRecords<byte[], byte[]> records = new ConsumerRecords<>(recordsMap);

    ConsumerRecords<String, String> filteredRecords = consumerRecordsProcessor.process(records);
    ConsumerRecord<String, String> consumerRecord = filteredRecords.iterator().next();
    assertEquals(filteredRecords.count(), 1, "Only one record should be there after filtering.");
    assertEquals(consumerRecord0.topic(), consumerRecord.topic(), "Topic should match");
    assertEquals(consumerRecord0.partition(), consumerRecord.partition(), "partition should match");
    assertTrue(Arrays.equals(consumerRecord0.key(), consumerRecord.key().getBytes()), "key should match");
    assertEquals(consumerRecord0.offset(), consumerRecord.offset(), "Offset should match");
    assertEquals(consumerRecord.value(), "message0", "\"message0\" should be the value");
  }

  @Test
  public void testCorrectness() {
    ConsumerRecordsProcessor<String, String> consumerRecordsProcessor = createConsumerRecordsProcessor();
    ConsumerRecords<String, String> processedRecords = consumerRecordsProcessor.process(getConsumerRecords());
    assertEquals(processedRecords.count(), 4, "There should be 4 records");
    Iterator<ConsumerRecord<String, String>> iter = processedRecords.iterator();
    assertEquals(iter.next().offset(), 0, "Message offset should b 0");
    assertEquals(iter.next().offset(), 2, "Message offset should b 2");
    assertEquals(iter.next().offset(), 4, "Message offset should b 4");
    assertEquals(iter.next().offset(), 5, "Message offset should b 5");
  }

  @Test
  public void testSafeOffsetWithoutLargeMessage() throws IOException {
    Serializer<String> stringSerializer = new StringSerializer();
    Serializer<LargeMessageSegment> segmentSerializer = new DefaultSegmentSerializer();
    ConsumerRecordsProcessor<String, String> consumerRecordsProcessor = createConsumerRecordsProcessor();

    // Let consumer record 0 and 1 be a normal record.
    // Let consumer record 0 be a normal record.
    byte[] message0Bytes = stringSerializer.serialize("topic", "message0");
    byte[] message0WrappedBytes = wrapMessageBytes(segmentSerializer, message0Bytes);
    ConsumerRecord<byte[], byte[]> consumerRecord0 =
        new ConsumerRecord<>("topic", 0, 0, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), message0WrappedBytes);

    // Let consumer record 1 be a normal message.
    byte[] message1Bytes = stringSerializer.serialize("topic", "message1");
    byte[] message1WrappedBytes = wrapMessageBytes(segmentSerializer, message1Bytes);
    ConsumerRecord<byte[], byte[]> consumerRecord1 =
        new ConsumerRecord<>("topic", 0, 1, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), message1WrappedBytes);

    // Construct the consumer records.
    TopicPartition tp = new TopicPartition("topic", 0);
    List<ConsumerRecord<byte[], byte[]>> recordList = new ArrayList<>();
    recordList.add(consumerRecord0);
    recordList.add(consumerRecord1);
    Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> recordsMap =
        new HashMap<>();
    recordsMap.put(tp, recordList);
    ConsumerRecords<byte[], byte[]> records = new ConsumerRecords<>(recordsMap);

    consumerRecordsProcessor.process(records);
    Map<TopicPartition, OffsetAndMetadata> safeOffsets = consumerRecordsProcessor.safeOffsetsToCommit();
    assertEquals(safeOffsets.size(), 1, "Safe offsets should contain one entry");
    assertEquals(safeOffsets.get(tp).offset(), 2, "Safe offset of topic partition 0 should be 2");
    assertEquals(consumerRecordsProcessor.safeOffset(tp, 0L).longValue(), 1, "safe offset should be 1");
    assertEquals(consumerRecordsProcessor.safeOffset(tp, 1L).longValue(), 2, "safe offset should be 2");

    Map<TopicPartition, OffsetAndMetadata> offsetMap = new HashMap<>();
    offsetMap.put(tp, new OffsetAndMetadata(1L));
    safeOffsets = consumerRecordsProcessor.safeOffsetsToCommit(offsetMap, false);
    assertEquals(safeOffsets.get(tp).offset(), 1L, "Safe offset of topic partition 0 should be 1");

    offsetMap.put(tp, new OffsetAndMetadata(2L));
    safeOffsets = consumerRecordsProcessor.safeOffsetsToCommit(offsetMap, false);
    assertEquals(safeOffsets.get(tp).offset(), 2L, "Safe offset of topic partition 0 should be 2");
  }

  @Test
  public void testSafeOffsetWithLargeMessage() throws IOException {
    ConsumerRecordsProcessor<String, String> consumerRecordsProcessor = createConsumerRecordsProcessor();
    consumerRecordsProcessor.process(getConsumerRecords());

    // check safe offsets
    TopicPartition tp = new TopicPartition("topic", 0);
    Map<TopicPartition, OffsetAndMetadata> safeOffsets = consumerRecordsProcessor.safeOffsetsToCommit();
    assertEquals(safeOffsets.size(), 1, "Safe offsets map should contain 1 entry");
    assertEquals(consumerRecordsProcessor.safeOffset(tp, 0L).longValue(), 1, "safe offset should be 1");
    try {
      consumerRecordsProcessor.safeOffset(tp, 1L);
      fail("Should throw exception because offset is invalid.");
    } catch (OffsetNotTrackedException onte) {
      assertTrue(onte.getMessage().startsWith("Offset 1 for partition"));
    }
    assertEquals(consumerRecordsProcessor.safeOffset(tp, 2L).longValue(), 1, "safe offset should be 1");
    try {
      consumerRecordsProcessor.safeOffset(tp, 3L);
      fail("Should throw exception because offset is invalid.");
    } catch (OffsetNotTrackedException onte) {
      assertTrue(onte.getMessage().startsWith("Offset 3 for partition"));
    }
    assertEquals(consumerRecordsProcessor.safeOffset(tp, 4L).longValue(), 1, "safe offset should be 1");
    assertEquals(consumerRecordsProcessor.safeOffset(tp, 5L).longValue(), 6, "safe offset should be 6");
    assertEquals(consumerRecordsProcessor.startingOffset(tp, 4L), 3, "Starting offset of large message 2 should be 3");
    assertEquals(consumerRecordsProcessor.startingOffset(tp, 5L), 1, "Starting offset of large message 1 should be 1");
    assertEquals(consumerRecordsProcessor.startingOffset(tp, 0L), 0, "Starting offset of large message 0 should be 0");
  }

  @Test
  public void testEviction() {
    Serializer<String> stringSerializer = new StringSerializer();
    Serializer<LargeMessageSegment> segmentSerializer = new DefaultSegmentSerializer();
    // Create two large messages.
    MessageSplitter splitter = new MessageSplitterImpl(500, segmentSerializer);

    ConsumerRecordsProcessor<String, String> consumerRecordsProcessor = createConsumerRecordsProcessor();
    consumerRecordsProcessor.process(getConsumerRecords());
    // The offset tracker now has 2, 4, 5 in it.
    TopicPartition tp = new TopicPartition("topic", 0);

    UUID largeMessageId = UUID.randomUUID();
    byte[] largeMessage1Bytes = stringSerializer.serialize("topic", TestUtils.getRandomString(600));
    List<ProducerRecord<byte[], byte[]>> splitLargeMessage =
        splitter.split("topic", largeMessageId, largeMessage1Bytes);

    // Test evict
    List<ConsumerRecord<byte[], byte[]>> recordList = new ArrayList<ConsumerRecord<byte[], byte[]>>();
    // Let consumer record 6 be a large message segment.
    ConsumerRecord<byte[], byte[]> consumerRecord6 =
        new ConsumerRecord<>("topic", 0, 6, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), splitLargeMessage.get(0).value());
    // Let consumer record 7 be a normal record.
    ConsumerRecord<byte[], byte[]> consumerRecord7 =
        new ConsumerRecord<>("topic", 0, 7, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(),
                             stringSerializer.serialize("topic", "message7"));
    // Let consumer record 8 completes consumer record 6
    ConsumerRecord<byte[], byte[]> consumerRecord8 =
        new ConsumerRecord<>("topic", 0, 8, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), splitLargeMessage.get(1).value());

    recordList.add(consumerRecord6);
    recordList.add(consumerRecord7);
    recordList.add(consumerRecord8);

    Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> recordsMap = new HashMap<>();
    recordsMap.put(new TopicPartition("topic", 0), recordList);
    ConsumerRecords<byte[], byte[]> records = new ConsumerRecords<>(recordsMap);
    consumerRecordsProcessor.process(records);
    // Now the offset tracker should have 4, 5, 6, 8 in side it.
    assertEquals(consumerRecordsProcessor.safeOffset(tp, 7L).longValue(), 6, "safe offset should be 6");

    try {
      consumerRecordsProcessor.safeOffset(tp, 2L);
      fail("Should throw exception because offset for message 2 should have been evicted.");
    } catch (OffsetNotTrackedException onte) {
      assertTrue(onte.getMessage().startsWith("Offset 2 for partition"));
    }
  }

  @Test
  public void verifyStartingOffset() {
    ConsumerRecordsProcessor<String, String> consumerRecordsProcessor = createConsumerRecordsProcessor();
    consumerRecordsProcessor.process(getConsumerRecords());

    TopicPartition tp = new TopicPartition("topic", 0);
    assertEquals(consumerRecordsProcessor.startingOffset(tp, 4L), 3, "Starting offset of large message 2 should be 3");
    assertEquals(consumerRecordsProcessor.startingOffset(tp, 5L), 1, "Starting offset of large message 1 should be 1");
    assertEquals(consumerRecordsProcessor.startingOffset(tp, 0L), 0, "Starting offset of large message 0 should be 0");
  }

  @Test
  public void testStartingOffsetWithoutMessages() throws IOException {
    ConsumerRecordsProcessor<String, String> consumerRecordsProcessor = createConsumerRecordsProcessor();

    TopicPartition tp = new TopicPartition("topic", 0);
    assertEquals(consumerRecordsProcessor.startingOffset(tp, 100L), 100, "Should return 100 because there are no " +
        "large messages in the partition.");
  }

  @Test(expectedExceptions = OffsetNotTrackedException.class)
  public void testStartingOffsetWithNormalMessages() throws IOException {
    Serializer<String> stringSerializer = new StringSerializer();
    Serializer<LargeMessageSegment> segmentSerializer = new DefaultSegmentSerializer();
    ConsumerRecordsProcessor<String, String> consumerRecordsProcessor = createConsumerRecordsProcessor();

    // Let consumer record 0 be a normal record.
    byte[] message0Bytes = stringSerializer.serialize("topic", "message0");
    byte[] message0WrappedBytes = wrapMessageBytes(segmentSerializer, message0Bytes);
    ConsumerRecord<byte[], byte[]> consumerRecord0 =
        new ConsumerRecord<>("topic", 0, 100L, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), message0WrappedBytes);

    // Construct the consumer records.
    List<ConsumerRecord<byte[], byte[]>> recordList = new ArrayList<>();
    recordList.add(consumerRecord0);
    Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> recordsMap = new HashMap<>();
    recordsMap.put(new TopicPartition("topic", 0), recordList);
    ConsumerRecords<byte[], byte[]> records = new ConsumerRecords<>(recordsMap);

    consumerRecordsProcessor.process(records);

    TopicPartition tp = new TopicPartition("topic", 0);
    assertEquals(consumerRecordsProcessor.startingOffset(tp, 100L), 100, "Should return 100 because there are no " +
        "large messages in the partition.");

    // Should throw exception when an offset cannot be found by the offset tracker.
    consumerRecordsProcessor.startingOffset(tp, 0L);
  }

  @Test
  public void testLastDelivered() {
    ConsumerRecordsProcessor<String, String> consumerRecordsProcessor = createConsumerRecordsProcessor();
    consumerRecordsProcessor.process(getConsumerRecords());

    assertEquals(consumerRecordsProcessor.delivered(new TopicPartition("topic", 0)).longValue(), 5L,
                 "The last deivered message should be 5");

    assertNull(consumerRecordsProcessor.delivered(new TopicPartition("topic", 1)));
  }

  private ConsumerRecords<byte[], byte[]> getConsumerRecords() {
    Serializer<String> stringSerializer = new StringSerializer();
    Serializer<LargeMessageSegment> segmentSerializer = new DefaultSegmentSerializer();
    // Create two large messages.
    MessageSplitter splitter = new MessageSplitterImpl(500, segmentSerializer);

    UUID largeMessageId1 = UUID.randomUUID();
    byte[] largeMessage1Bytes = stringSerializer.serialize("topic", TestUtils.getRandomString(600));
    List<ProducerRecord<byte[], byte[]>> splitLargeMessage1 =
        splitter.split("topic", largeMessageId1, largeMessage1Bytes);

    UUID largeMessageId2 = UUID.randomUUID();
    byte[] largeMessage2Bytes = stringSerializer.serialize("topic", TestUtils.getRandomString(600));
    List<ProducerRecord<byte[], byte[]>> splitLargeMessage2 =
        splitter.split("topic", largeMessageId2, largeMessage2Bytes);

    // Let consumer record 0 be a normal record.
    ConsumerRecord<byte[], byte[]> consumerRecord0 =
        new ConsumerRecord<>("topic", 0, 0, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), stringSerializer.serialize("topic", "message0"));
    // Let consumer record 1 be a large message segment
    ConsumerRecord<byte[], byte[]> consumerRecord1 =
        new ConsumerRecord<>("topic", 0, 1, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), splitLargeMessage1.get(0).value());
    // Let consumer record 2 be a normal message
    ConsumerRecord<byte[], byte[]> consumerRecord2 =
        new ConsumerRecord<>("topic", 0, 2, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), stringSerializer.serialize("topic", "message1"));
    // Let record 3 be a new large message segment
    ConsumerRecord<byte[], byte[]> consumerRecord3 =
        new ConsumerRecord<>("topic", 0, 3, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), splitLargeMessage2.get(0).value());
    // let record 4 completes record 3
    ConsumerRecord<byte[], byte[]> consumerRecord4 =
        new ConsumerRecord<>("topic", 0, 4, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), splitLargeMessage2.get(1).value());
    // let record 5 completes record 1
    ConsumerRecord<byte[], byte[]> consumerRecord5 =
        new ConsumerRecord<>("topic", 0, 5, 0L, TimestampType.CREATE_TIME, 0, 0, 0, "key".getBytes(), splitLargeMessage1.get(1).value());

    // Construct the consumer records.
    List<ConsumerRecord<byte[], byte[]>> recordList = new ArrayList<>();
    recordList.add(consumerRecord0);
    recordList.add(consumerRecord1);
    recordList.add(consumerRecord2);
    recordList.add(consumerRecord3);
    recordList.add(consumerRecord4);
    recordList.add(consumerRecord5);
    Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> recordsMap =
        new HashMap<>();
    recordsMap.put(new TopicPartition("topic", 0), recordList);
    return new ConsumerRecords<>(recordsMap);
  }

  private ConsumerRecordsProcessor<String, String> createConsumerRecordsProcessor() {
    Deserializer<String> stringDeserializer = new StringDeserializer();
    Deserializer<LargeMessageSegment> segmentDeserializer = new DefaultSegmentDeserializer();
    MessageAssembler assembler = new MessageAssemblerImpl(5000, 100, false, segmentDeserializer);
    DeliveredMessageOffsetTracker deliveredMessageOffsetTracker = new DeliveredMessageOffsetTracker(4);
    return new ConsumerRecordsProcessor<>(assembler, stringDeserializer, stringDeserializer,
                                          deliveredMessageOffsetTracker, null);
  }

  private byte[] wrapMessageBytes(Serializer<LargeMessageSegment> segmentSerializer, byte[] messageBytes) {
    return segmentSerializer.serialize("topic",
                                       new LargeMessageSegment(UUID.randomUUID(), 0, 1, messageBytes.length,
                                                               ByteBuffer.wrap(messageBytes)));
  }
}
